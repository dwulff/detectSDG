---
title: "Using text2sdg"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{using_text2sdg}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=7, fig.height=4
)
```

```{r setup}
library(text2sdg)
```

The aim of the `text2sdg` package ... SAY A BIT MORE ON QUERY SYSTEMS ...


The `text2sdg` package consists of three core functions: `detect_sdg()`, `plot_sdg()`, and `crosstab_sdg()`. The function `detect_sdg()` carries out the detection SDGs in text, while the functions `plot_sdg()`, and `crosstab_sdg()` help visualize and analyze the resulting SDG matches. This vignette first demonstrates `detect_sdg()`, before turning to `plot_sdg()` and `crosstab_sdg()`. 

The `detect_sdg()` function identifies SDGs in texts that are provided as character vector (or an object of `tCorpus` from package `corpustools`) and returns a `tibble` reporting the matches found in each document. Several optional arguments can be used to se. The argument `sdgs` lets you specify using a numeric vector which SDGs shall be identified in the text. For instance, with `sdgs = 1:5` the function will only detect SDGs one to five. Note that this can significantly speed up runtime if you are only interetsed in a subset of the sDGs. Per default the function will identify either all 16 or 17 SDGs depending on the query system. The argument `systems`  lets you specify which query systems will be used to detect the SDGs in the text. By default, all systems excluding ontology will be employed. Systems will be run independently of each other, implying that the results can differ between systems. The output will distinguish systems using a dedicated variable. The argument `systems` can be used to specify any subset of the four query systems available, e.g., `systems = c("aurora")` will run only aurora queries.  The argument `output` allows you to control the level of aggregation in the `tibble` that `detect_sgd()` returns. The default `features` returns a `tibble` with one row per matched query, include a variable containing the features of the query that were matched in the text. By contrast, `docs` returns an aggregated `tibble` with one row per matched sdg, without information on the features that produced the hits. Finally, the `verbose` argument let's you specify whether you want to be informed about the function's progress with printed messages, it defaults to `TRUE`.

We demonstrate the use of `detect_sdg` using the `abstracts` data set included in the `text2sdg` package. It includes 100 abstracts from academic publications. To detect all SDGs in the abstracts using all systems, run the following code. 

```{r}
# detecting SDGs in abstracts
sdgs_default <- detect_sdg(abstracts)

# print result tibble
sdgs_default
```

Since `verbose = TRUE` by defaul, the function is informs us that the SDGs are identified system by system, and after a few seconds we see the resulting output (a tibble with six columns). The output tells us which SDG was detected in which document by which system (columns one to three). It also tells us which query and features produced the hit. The last column is the hit index for a given system. 

This output is informative, but does not provide a good overview of which sDGs have been detected in the text. This is where the `plot_sdg()` function comes into play. `plot_sdg()` takes the output of `detect_sdg()` as input.
```{r}
plot_sdg(sdgs_default)
```

The output of `plot_sdg()` is a stacked bar chart that shows you how often a SDG was detected by a given system in the text that you fed to `detect_sdg()`. There are a few more arguments that you can specify. As with the `detect_sdg()` function, you can subset the systems and SDGs that you want to show with `systems` and `sdgs` respectively. The `normalize` argument allows you to normalize the frequencies using either the total frequencies of each system `normalize = "systems"` or the total number of documents `normalize = "documents"`. There are a few more arguments that allow you to customize the appearance of the plot. The plot below shows you the normalized frequency (by system) of SDGs 03, 10, and 13 for the systems Aurora and Elsevier and sdsn.
```{r}
plot_sdg(sdgs_default, sdgs = c(3, 10, 13), systems = c("aurora", "elsevier", "sdsn"), normalize = "documents")
```


Once you have an overiview about which SDGs were matched how often by which system, you might want to see which SDGs co-occured in the text. You can do this with the `crosstab_sdg()` function. It also takes the output of `detect_sdg()` as input.

```{r}
sdg_corr <- crosstab_sdg(sdgs_default, compare = "sdgs")
```

The output is a correlation matrix, which we visualize with the `corrplot()` function from the `corrplot` package. 

```{r}
corrplot::corrplot(sdg_corr)
```

Like this we can easily see which SDGs co-occur in the text and which do not. As with the previous functions, we can subset both the SDGs and the systems (with the same arguments as in the other functions).

You might also be interested in whether the different systems reach similar conlusions regarding whether an SDG is present in your documents or not. We can also use the `crosstab_sdg()` function for this but specify `compare = "systems"`.

```{r}
systems_corr <- crosstab_sdg(sdgs_default, compare = "systems")
corrplot::corrplot(systems_corr)
```

We see that all but the Elsevier and Aurora systems correlate positively with each other, meaning they reach similar conclusions regarding whether a SDG is present in a document or not. 



